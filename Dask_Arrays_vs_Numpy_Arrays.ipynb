{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dask Arrays vs Numpy Arrays.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN/r8dIcYLOClPqO4I0JaOp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AceroMike/Big-Data/blob/main/Dask_Arrays_vs_Numpy_Arrays.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88FhKiOljaHg"
      },
      "source": [
        "Dask allows us to speed up computation time because it parallelizes the computations. That means that it can run multiple smaller computations simulataneously. NumPy, like Pandas, does not parallelize. But instead works on memory. Working on memory is great if you have the space for it but Dask let's you run computations on data that would not fit to memory. As we will see, parallelizing with Dask arrays will lead to faster compute times than working with NumPy arrays. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpSwKc9kkGbS",
        "outputId": "17640476-5b69-405c-8c06-13e8bcd32d06"
      },
      "source": [
        "# Installations\r\n",
        "\r\n",
        "!pip install dask[complete] --quiet\r\n",
        "!pip install dask distributed --upgrade --quiet\r\n",
        "!pip install aiohttp --quiet\r\n",
        "!pip install dask-ml --quiet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 675kB 10.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 27.5MB/s \n",
            "\u001b[31mERROR: distributed 2021.3.0 has requirement cloudpickle>=1.5.0, but you'll have cloudpickle 1.3.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: distributed 2021.3.0 has requirement dask>=2021.03.0, but you'll have dask 2.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 931kB 12.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3MB 13.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 296kB 43.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 47.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 12.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 22.3MB 1.7MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc7zufbBjXSI"
      },
      "source": [
        "# Imports\r\n",
        "import numpy as np\r\n",
        "import dask.array as da"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxHHP-T3kUKi"
      },
      "source": [
        "We will be comparing the runtimes for Numpy and Dask array operations on some made up data. Now let's create the data. \r\n",
        "\r\n",
        "1. Let's create a 10,000 x 10,000 array of random numbers\r\n",
        "2. Then we will add this array with it's transpose\r\n",
        "3. Filter the resulting array and calculate its mean\r\n",
        "\r\n",
        "Remember, that we have to use `.compute()` for Dask to evaluate the results. Also notice that we will be setting the chunks parameter. This simply tells Dask how to partition the data into NumPy arrays. In this case, we will have 100 NumPy arrays of size 1000 x 1000. We will be changing these parameters to see how our time change. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mng1gPWbkTLA",
        "outputId": "462a157c-3a37-46d7-a0c6-171dd1127a2e"
      },
      "source": [
        "# With Dask\r\n",
        "%time\r\n",
        "x = da.random.random((10000,10000), chunks=(1000,1000))\r\n",
        "y = x + x.T\r\n",
        "z = y[::2, 5000:].mean(axis=1)\r\n",
        "z.compute()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 6.68 µs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.00436239, 1.00289961, 0.99869341, ..., 0.98985282, 0.99361362,\n",
              "       1.01671068])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u3kGe8SltFb",
        "outputId": "b7021bbd-0d0f-452f-a9dc-b072199fc63b"
      },
      "source": [
        "# With NumPy\r\n",
        "%%time\r\n",
        "x = np.random.random((10000, 10000))\r\n",
        "y = x + x.T\r\n",
        "z = y[::2, 5000:].mean(axis=1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.41 s, sys: 439 ms, total: 1.85 s\n",
            "Wall time: 1.85 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPQCpPTgly9x"
      },
      "source": [
        "As we can see, thanks to parallelization, we are able to run the same computation faster with Dask than with NumPy. Now we want to see how the computation times change when we adjust the array we are working with. We will change the chunk size first to 500x500 and then to 250x250. Each time we reduce the chunk size our Dask array will have more individual Numpy arrays. Will this make computations faster? or slower?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oocg0e-tm-Te",
        "outputId": "de9c3f80-7ae2-42cd-89b5-bbbc04700c30"
      },
      "source": [
        "%%timeit\r\n",
        "x = da.random.random((10000, 10000), chunks=(500, 500))\r\n",
        "y = x + x.T\r\n",
        "z = y[::2, 5000:].mean(axis=1)\r\n",
        "z.compute()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 5: 1.04 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-db-OqlJlw_T",
        "outputId": "e5cd648e-bf27-4dcd-cfdc-f01a1d69174d"
      },
      "source": [
        "%%timeit\r\n",
        "x = da.random.random((10000, 10000), chunks=(250, 250))\r\n",
        "y = x + x.T\r\n",
        "z = y[::2, 5000:].mean(axis=1)\r\n",
        "z.compute()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 5: 1.8 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMjcE421nE8f"
      },
      "source": [
        "As we might have expected, there is some diminishing returns to parralelization. If we ask Dask to divide the data too much then it will take even longer to run the computations. Setting the chunk size to a larger number leads to faster results because it leads to fewer computations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUTCyuQCnaEW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}